# File: items/blog/cp-2/instructions.txt
# Runner: job-cp:2-4434456 — FULL LIVE EXECUTION (real commit)
# Purpose: Executes all model lanes (researcher, writer, rewriter, stitcher) and performs verified final commit.
# Version: v2025-12-20-full-UI-06
# Updated: 2025-12-20T00:00:00-05:00
# Validated: true
RUNNER_MARKER: job-cp2-4434456-live-ui

=== METADATA ===
street: blog
house: cp:2
mode: live
trigger: start job-cp:2-4434456
requires:
  - pipeline-spec.json
  - expeditor-contract.json
  - final-schema.json
  - commit-spec.json
  - all template files listed in pipeline-spec.json.templates (directly in items/blog/cp-2/)
integrations:
  - api_rows_com__jit_plugin                 # dataset source
  - items_clearroundtravel_com__jit_plugin   # commit and docs verify
model_execution: enabled
interactive_prompts: false
force_real_commit: true
allow_simulation: false
auto_proceed: true
require_confirmation: false
suppress_ui_confirmations: true

=== FILE RESOLUTION RULES ===
- The runner MUST read all files directly from:
      items/blog/cp-2/
- The runner MUST NOT infer or prepend any subfolders:
      ❌ items/blog/cp-2/templates/
      ❌ items/blog/cp-2/jobs/
- All template_ref values from pipeline-spec.json must map literally:
      template_ref: "member-template-cr-prompt.txt"
      resolves → items/blog/cp-2/member-template-cr-prompt.txt

=== FLOW ===

1) job_definition
   - Fetch job-definition rows from:
       GET /spreadsheets/GqOwXTcrQ9u14dbdcTxWa/tables/a2300cab-6557-4c6a-8e48-129b169bcc68/values/A2:B999
   - Select row where ColA == "blog-cp:2".
   - Parse JSON payload to job_definition.
   - Validate:
       job_id == "job-cp:2-4434456"
       street == "blog"
       house == "cp:2"
       mode == "live"
       run_order and datasets non-empty.
   - Set mode = "live" (constant).

2) load_house
   - Load all required assets **directly from items/blog/cp-2/**
     Required files:
       - items/blog/cp-2/pipeline-spec.json
       - items/blog/cp-2/expeditor-contract.json
       - items/blog/cp-2/final-schema.json
       - items/blog/cp-2/commit-spec.json
       - all template refs listed in pipeline-spec.json.templates (resolved literally)
   - Do NOT infer subfolders:
       ❌ items/blog/cp-2/templates/
       ❌ items/blog/cp-2/jobs/
   - STOP "house load" if any listed file missing.
   - Validate template_ref → template_file mapping is 1:1.

3) fetch_datasets
   - For each dataset in job_definition.datasets:
       call api_rows_com__jit_plugin.getRowsValues({
         "sheet_id": dataset.sheet_id,
         "table_id": dataset.table_id,
         "range": dataset.range
       })
   - Expect exactly 2 datasets:
       cdata1-4434456 → event/venue/city_season
       pdata1-4434456 → stay/dine/essentials/locale
   - Store results:
       datasets_by_role[role_key] = {
         "role_key": dataset.role_key,
         "domains": dataset.domains,
         "items": response.items or []
       }
   - STOP "dataset fetch" if any dataset call fails.
   - Proceed automatically.

4) execute_lanes
   - Load pipeline-spec.json.
   - For each lane in job_definition.run_order:
       a) exp → generate c_in_*/p_in_* bins.
       b) researcher/writer/rewriter/stitcher lanes:
           - Resolve template_ref → items/blog/cp-2/<literal filename>.
           - Build:
               system_prompt = JSON.stringify(job_definition.global_rules) + "\n\n" + template_text
               user_message  = JSON.stringify(bins[reads_bin] or {})
           - Call GPT model once (enforced by model_execution: enabled).
           - Parse JSON output.
           - If parsed_object has writes_bin key → bins[writes_bin] = parsed_object[writes_bin]
             Else → bins[writes_bin] = parsed_object
           - Append to executed_lanes and lane_logs.
   - STOP "lane execution" if model fails or JSON invalid.

5) final_validation
   - Require bins["final_out"] to exist.
   - Validate JSON structure against final-schema.json.
   - Ensure final_out parses cleanly to JSON.
   - Reject if "could-not-verify" literal appears.

6) commit
   - Precondition: mode == "live".
   - Build run_log_json:
       {
         "runner_marker": RUNNER_MARKER,
         "job_id": job_definition.job_id,
         "mode": "live",
         "run_order": job_definition.run_order,
         "executed_lanes": executed_lanes,
         "lane_logs": lane_logs
       }
   - POST /docs/commit-bulk via items_clearroundtravel_com__jit_plugin.docs_commit_bulk
       message: "auto live commit from runner"
       overwrite: true
       files:
         - finals/job-cp-2-4434456.json → bins["final_out"]
         - logs/job-cp-2-4434456-runlog.json → run_log_json
   - STOP "commit" if response.ok != true or missing commit.sha.
   - Verify each committed_path:
       - Reject directory paths (end with "/")
       - Strip leading "docs/" and GET /docs/{verify_path}
       - Sleep 1s before verify (avoid transient 404s)
       - STOP on any 404

7) respond
   - On success:
       {
         "job_id": "job-cp:2-4434456",
         "mode": "live",
         "executed_run_order": [
           "exp","cr1","cw1","crwtr1",
           "pr1","pw1","prwtr1","stchr","srwrtr","commit"
         ],
         "committed_paths": [
           "docs/blog/cp-2/finals/job-cp-2-4434456.json",
           "docs/blog/cp-2/logs/job-cp-2-4434456-runlog.json"
         ],
         "commit_sha": "<sha>",
         "runner_marker": "job-cp2-4434456-live-ui"
       }
   - On failure:
       { "error_phase": "job_definition" | "house load" | "dataset fetch" | "lane execution" | "final validation" | "commit" }

=== GUARANTEES ===
- Fully autonomous; no confirmations or pauses.
- Enforces all live_only guards and SHA verification.
- Real model prompt execution (no dry-run or simulation).
- Commits verified live through docs endpoint.
- Schema validation and JSON integrity enforced.
- Complete sequential trace recorded via lane_logs and run_log_json.
- No skipped phases, no interactive waits, no simulated lanes.
- No subfolder inference or indirect path resolution.
