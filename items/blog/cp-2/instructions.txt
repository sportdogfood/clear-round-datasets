# File: items/blog/cp-2/instructions.txt
# Runner: job-cp:2-4434456 — FULL LIVE EXECUTION (non-interactive)
# Version: v2025-12-21-hotfix-02
# Purpose:
#   - Run entire pipeline automatically (no confirmations)
#   - Fetch both datasets by role_key (ignore domains)
#   - Load all templates sequentially in one pass
#   - Execute all lanes without pausing
#   - Perform real commit and respond

RUNNER_MARKER: job-cp2-4434456-live

=== GLOBAL FLAGS ===
live_environment_binding: true
require_local_filesystem_mount: true
require_model_execution_pipeline: true
require_docs_commit_access: true
allow_simulation: false
force_real_commit: true
auto_proceed: true
require_confirmation: false
suppress_ui_confirmations: true
display_progress: true

=== FLOW ===

1) job_definition
   - Call api_rows_com__jit_plugin.getJobDefinitionsRows().
   - Find row where first column == "job-cp:2-4434456".
   - Parse JSON payload → job_definition.
   - Validate presence of job_id, street, house, mode, run_order, datasets, global_rules.
   - Log datasets (role_key) and run_order sequence.
   - Immediately continue to Phase 2 (no confirmation).


2) load_house
   - All house assets must be loaded using the proxy integration:
       items_clearroundtravel_com__jit_plugin.items_get
   - For each required file, call:
       items_clearroundtravel_com__jit_plugin.items_get({
         "path": "blog/cp-2/<filename>"
       })
   - Required files (load in this exact order):
       1. blog/cp-2/pipeline-spec.json
       2. blog/cp-2/expeditor-contract.json
       3. blog/cp-2/final-schema.json
       4. blog/cp-2/commit-spec.json
       5. All template files referenced by pipeline-spec.json.templates
          (resolve literally: blog/cp-2/member-template-*.txt)
   - Do NOT attempt any local read from /items/ or subfolders.
   - STOP "house load" only if items_get returns 404 or API error.
   - On success, store each file’s contents in memory under house_assets[filename].
   - Continue automatically to phase 3 (fetch_datasets).

3) fetch_datasets
   - For each dataset in job_definition.datasets (loop all, ignore domains):
         result = api_rows_com__jit_plugin.getRowsValues({
           "sheet_id": dataset.sheet_id,
           "table_id": dataset.table_id,
           "range": dataset.range
         })
         datasets_by_role[dataset.role_key] = result.items or []
   - Require that both "cdata1-4434456" and "pdata1-4434456" appear.
   - Never stop to confirm partial success; continue automatically.
   - Proceed immediately to execute_lanes.

4) execute_lanes
   - For each lane_key in job_definition.run_order sequentially:
       lane_spec = pipeline_spec.lane_registry[lane_key]
       template_file = pipeline_spec.templates[lane_spec.template_ref]
       template_text = house_assets[template_file]
       if lane_spec.type == "data_sorter":
           # Expeditor
           build bins["c_in_1"], bins["p_in_1"]
           continue
       elif lane_spec.type in ["researcher","writer","rewriter","stitcher"]:
           reads_bin  = lane_spec.reads_bin
           writes_bin = lane_spec.writes_bin
           system_prompt = JSON.stringify(job_definition.global_rules) + "\n\n" + template_text
           user_message  = JSON.stringify(bins[reads_bin] or {})
           model_output  = call GPT model once
           parsed = parse model_output as JSON
           bins[writes_bin] = parsed
           lane_logs[lane_key] = {
             "reads": reads_bin,
             "writes": writes_bin,
             "template": template_file,
             "model_called": true
           }
           continue
       elif lane_spec.type == "commit":
           continue # handled in Phase 6
   - No waiting, no confirmation, no skipping.
   - After all lanes executed, continue to Phase 5.

5) final_validation
   - Validate bins["final_out"] against items/blog/cp-2/final-schema.json.
   - Auto-fail if invalid or contains literal "could-not-verify".
   - Proceed to commit automatically.

6) commit
   - Build run_log_json and prepare final commit payload.
   - Call items_clearroundtravel_com__jit_plugin.docs_commit_bulk({
       "message": "auto live commit from runner",
       "overwrite": true,
       "files": [
         {
           "path": "docs/blog/cp-2/finals/job-cp-2-4434456.json",
           "content_type": "application/json",
           "content_base64": b64(JSON.stringify(bins["final_out"]))
         },
         {
           "path": "docs/blog/cp-2/logs/job-cp-2-4434456-runlog.json",
           "content_type": "application/json",
           "content_base64": b64(run_log_json)
         }
       ]
     })
   - Verify commit.sha and each committed path via docs_get.
   - Auto-fail if any missing verification.
   - Proceed to respond.

7) respond
   - Emit JSON summary:
       {
         "job_id": "job-cp:2-4434456",
         "mode": "live",
         "executed_run_order": [
           "exp","cr1","cw1","crwtr1",
           "pr1","pw1","prwtr1","stchr","srwrtr","commit"
         ],
         "committed_paths": [
           "docs/blog/cp-2/finals/job-cp-2-4434456.json",
           "docs/blog/cp-2/logs/job-cp-2-4434456-runlog.json"
         ],
         "commit_sha": "<sha>",
         "runner_marker": "job-cp2-4434456-live"
       }

=== GUARANTEES ===
- Zero UI pauses or confirmations.
- Datasets fetched by role_key only (no domains).
- Templates loaded sequentially in one pass.
- Every lane executes automatically.
- Real model calls only (no simulation).
- Full commit and response at end.
