# File: items/blog/cp-2/instructions.txt
# Runner: job-cp:2-4434456 — FULL LIVE EXECUTION (real commit)
# Purpose: Executes all model lanes (researcher, writer, rewriter, stitcher) and commits verified outputs.
# Behavior: Fully autonomous — no stops, no confirmations, no interactive prompts.
# Version: v2025-12-21-full-CORE-11
# Updated: 2025-12-21T04:00:00-05:00
RUNNER_MARKER: job-cp2-4434456-live-core

=== ENVIRONMENT FLAGS ===
live_environment_binding: true
sandbox_fallback_allowed: false
require_model_execution_pipeline: true
require_docs_commit_access: true
require_local_filesystem_mount: false
fallback_to_simulation_on_failure: false
auto_proceed_all_phases: true
interactive_prompts: false
allow_simulation: false
force_real_commit: true
require_confirmation: false

=== METADATA ===
street: blog
house: cp:2
mode: live
trigger: start job-cp:2-4434456
requires:
  - pipeline-spec.json
  - expeditor-contract.json
  - final-schema.json
  - commit-spec.json
integrations:
  - api_rows_com__jit_plugin
  - items_clearroundtravel_com__jit_plugin
model_execution: enabled

=== FLOW ===

1) job_definition
   - Call api_rows_com__jit_plugin.getJobDefinitionsRows().
   - Find row where ColA == "job-cp:2-4434456".
   - Parse ColB JSON → job_definition.
   - Validate presence of: job_id, street, house, mode, run_order, datasets, global_rules.
   - Display:
       ✅ job_definition loaded (job_id: job-cp:2-4434456)
       Datasets: list dataset.role_key values
       Run order: exp → cr1 → cw1 → crwtr1 → pr1 → pw1 → prwtr1 → stchr → srwrtr → commit
   - Proceed immediately to Phase 2 (load_house). Never stop or prompt.

2) load_house
   - For each required file, call:
       items_clearroundtravel_com__jit_plugin.items_get({
         "path": "blog/cp-2/<filename>"
       })
   - Required files:
       - blog/cp-2/pipeline-spec.json
       - blog/cp-2/expeditor-contract.json
       - blog/cp-2/final-schema.json
       - blog/cp-2/commit-spec.json
       - all template refs listed in pipeline-spec.json.templates
   - Expected templates:
       member-template-cr-prompt.txt
       member-template-cw-prompt.txt
       member-template-crwtr-prompt.txt
       member-template-pr-prompt.txt
       member-template-pw-prompt.txt
       member-template-prwtr-prompt.txt
       member-template-stchr-prompt.txt
       member-template-srwrtr-prompt.txt
   - Do NOT infer or search subfolders.
   - If any call returns 404 → emit error_code: HOUSE_FILE_NOT_FOUND and continue to respond.
   - Store all file contents in memory as `house_assets[filename]`.
   - Proceed automatically to Phase 3.

3) fetch_datasets
   - For each dataset entry in job_definition.datasets:
       call api_rows_com__jit_plugin.getRowsValues({
         "sheet_id": dataset.sheet_id,
         "table_id": dataset.table_id,
         "range": dataset.range
       })
   - Do NOT inspect or validate dataset.domains.
   - Do NOT apply pipeline-spec.dataset_families filters.
   - Store results as:
       datasets_by_role[dataset.role_key] = response.items or []
   - Expect:
       - cdata1-4434456
       - pdata1-4434456
   - Continue automatically after all fetches.
   - On API failure → output error JSON and continue to respond.

4) execute_lanes
   - Execute all lanes in job_definition.run_order sequentially:
       exp → cr1 → cw1 → crwtr1 → pr1 → pw1 → prwtr1 → stchr → srwrtr → commit
   - Each lane:
       • Resolve template filename from pipeline-spec.templates.
       • Build system_prompt = JSON.stringify(job_definition.global_rules) + "\n\n" + template_text
       • Build user_message = JSON.stringify(bins[reads_bin] or {})
       • Call GPT model (model_execution: enabled).
       • Parse response JSON → bins[writes_bin].
       • Append lane log entry.
   - Never stop or prompt between lanes.
   - Continue directly to Phase 5.

5) final_validation
   - Validate bins["final_out"] against final-schema.json.
   - If invalid JSON or missing keys → emit error JSON.
   - Continue automatically.

6) commit
   - Perform live commit using:
       items_clearroundtravel_com__jit_plugin.docs_commit_bulk({
         "message": "auto live commit from runner",
         "overwrite": true,
         "files": [
           { "path": "docs/blog/cp-2/finals/job-cp-2-4434456.json", "content_base64": b64(bins["final_out"]) },
           { "path": "docs/blog/cp-2/logs/job-cp-2-4434456-runlog.json", "content_base64": b64(run_log_json) }
         ]
       })
   - Verify commit.sha and committed_paths automatically.
   - On commit failure → emit error JSON, then proceed to respond.

7) respond
   - Emit final JSON payload automatically:
       {
         "job_id": "job-cp:2-4434456",
         "mode": "live",
         "executed_run_order": [
           "exp","cr1","cw1","crwtr1",
           "pr1","pw1","prwtr1","stchr","srwrtr","commit"
         ],
         "committed_paths": [
           "docs/blog/cp-2/finals/job-cp-2-4434456.json",
           "docs/blog/cp-2/logs/job-cp-2-4434456-runlog.json"
         ],
         "commit_sha": "<sha>",
         "runner_marker": "job-cp2-4434456-live-core"
       }

=== GUARANTEES ===
- Executes full pipeline automatically from start to finish.
- No pauses, confirmations, or user interaction at any phase.
- Fetches all datasets defined in job_definition (ignoring domains).
- Loads all house assets directly from CRT proxy via items_get.
- Enforces live-only mode with verified commit at end.
- Performs schema and output validation automatically.
- Emits raw JSON error responses for failed phases, never stops mid-run.
- No simulation, no dry-run, no human checkpoints.
