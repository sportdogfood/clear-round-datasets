# File: items/blog/cp-2/instructions-mini.txt
# Runner: blog-cp:2 — MINI (end-to-end)
# Version: v2025-12-11-min-03
# Updated: 2025-12-11T17:10:00Z

# PURPOSE
# - Trigger: "start blog-cp:2"
# - Load job_definition from Rows (including mode)
# - Load cp:2 house files
# - Fetch datasets defined in job_definition
# - Hand off full pipeline (exp → crr → cwr → prr → pwr → rwt) to git.brains
# - Commit final JSON + HTML (+ log) using job_definition.paths.docs_finals_root / docs_logs_root
# - Send ONE final success/failure summary to the user

============================================================
1. TRIGGER
============================================================

Accept only:

- start blog-cp:2

On anything else: do nothing.

Let:
- street_token = "blog"
- house_token  = "cp:2"

============================================================
2. LOAD job_definition (Rows)
============================================================

Call Rows:

- GET /spreadsheets/GqOwXTcrQ9u14dbdcTxWa/tables/a2300cab-6557-4c6a-8e48-129b169bcc68/values/A2:B999

Interpret:
- column A (items[row][0]) = trigger key
- column B (items[row][1]) = JSON string

Find row where:
- items[row][0] == "blog-cp:2"

Parse items[row][1] → job_definition.

Minimal checks:
- job_definition.street == "blog"
- job_definition.house  == "cp:2"
- job_definition.run_order is array
- job_definition.datasets is non-empty
- job_definition.paths.docs_finals_root starts with "docs/"

Derive:
- mode = job_definition.mode if present, else "live"

If any check fails:
- STOP and reply with a short error message.
Else keep job_definition and mode in memory.

============================================================
3. LOAD HOUSE FILES (cp:2)
============================================================

Use house_root from runner.txt:

- house_root = "items/blog/cp-2/"

Read (for internal use only):

- pipeline-spec.json
- style-spec.json
- expeditor-contract.json
- final-schema.json
- commit-spec.json
- checker.json
- member-template-cr.prompt
- member-template-cw.prompt
- member-template-pr.prompt
- member-template-pw.prompt
- member-template-rwt.prompt
- instructions.txt

Notes:
- pipeline-spec.json defines lane names, types, and prompt_file for each lane.
- final-schema.json is enforced by git.brains / rwt, not by this MINI.

If final-schema.json or any required member-template is missing:
- STOP and tell user: house not fully configured.

No user messages yet.

============================================================
4. FETCH DATASETS (Rows)
============================================================

From job_definition.datasets, for each dataset:

- role_key
- domains
- sheet_id
- table_id
- range

Call Rows:

- GET /spreadsheets/{sheet_id}/tables/{table_id}/values/{range}

Store in memory:

- datasets_by_role[role_key] = {
    "role_key": role_key,
    "domains": domains,
    "items": <rows from Rows>
  }

If any dataset fetch fails:
- STOP and send a short error naming the failing role_key.

Still no progress updates to user.

============================================================
5. CALL git.brains FOR cp:2
============================================================

The MINI does NOT execute exp / crr / cwr / prr / pwr / rwt itself.
It delegates the full pipeline to git.brains.

Build one request payload:

brains_request = {
  "runner_id": "blog-cp:2",
  "mode": mode,                       # "live" or "sandbox"
  "job_definition": job_definition,   # as loaded in step 2
  "datasets_by_role": datasets_by_role
}

Send brains_request to the configured cp:2 brains endpoint
(implementation-specific; outside this MINI file).

Expect a JSON response of the form:

{
  "job_id": "<job-4434456>",
  "final_json": { ... },          # rwt-equivalent final tree
  "lane_logs": {                  # OPTIONAL per-lane logs
    "crr_output": { ... },
    "cwr_output": { ... },
    "prr_output": { ... },
    "pwr_output": { ... },
    "rwt_output": { ... }
  }
}

Minimal checks:

- response.job_id == job_definition.job_id
- response.final_json is a JSON object

If any check fails:
- STOP and send a concise error naming "brains pipeline" as failing phase.

If OK:

- state.rwt_output = response.final_json
- state.lane_logs  = response.lane_logs (may be null/empty)

No user messages yet.

============================================================
6. COMMIT FINAL JSON + HTML + LOG
============================================================

From job_definition.paths:

- finals_root = job_definition.paths.docs_finals_root
  (e.g. "docs/blog/cp-2/finals/")
- logs_root   = job_definition.paths.docs_logs_root
  (e.g. "docs/blog/cp-2/logs/")
- job_id      = job_definition.job_id

Derive:

- json_path = finals_root + job_id + ".json"
- html_path = finals_root + job_id + ".html"
- log_path  = logs_root   + job_id + "-rwt.json"

Build:

- final_json = JSON(state.rwt_output)

- html_output = HTML string rendering the main paragraphs, for example:

  <html>
    <body>
      <p>{{collection_body.paragraph_1}}</p>
      <p>{{collection_body.paragraph_2}}</p>

      <hr />

      <p>{{places_body.stay_paragraph}}</p>
      <p>{{places_body.dine_paragraph}}</p>
      <p>{{places_body.essentials_paragraph}}</p>
      <p>{{places_body.locale_paragraph}}</p>
      <p>{{places_body.outro_paragraph}}</p>
    </body>
  </html>

- log_json = JSON({
    "job_id": job_id,
    "mode": mode,
    "run_order": job_definition.run_order,
    "lane_logs": state.lane_logs
  })

Base64-encode all three and call docs_commit_bulk (per commit-spec.json):

- message:   "Final commit for " + job_id
- overwrite: true
- files:
  - { path: json_path, content_type: "application/json", content_base64: <json> }
  - { path: html_path, content_type: "text/html",        content_base64: <html> }
  - { path: log_path,  content_type: "application/json", content_base64: <log_json> }

If commit fails:
- STOP and send a concise error to the user.

============================================================
7. USER RESPONSE (ONE MESSAGE)
============================================================

If everything succeeds:

- Send ONE summary message:
  - job_id
  - mode
  - executed run_order
  - final JSON path
  - final HTML path
  - log JSON path
  - commit SHA (if returned)

If anything fails earlier:
- Send ONE concise error, naming:
  - failing phase (job load, datasets, brains pipeline, commit)
  - minimal reason.

No step-by-step progress chatter; only final success or failure.
